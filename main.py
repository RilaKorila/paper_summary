#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# raycast.title = Create Obsidian Paper Note
# raycast.mode = compact
# raycast.argument1.label = URL
# raycast.argument1.type = text

import sys
import os
import requests
from bs4 import BeautifulSoup
from datetime import date
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv('config.env')

# Gemini APIè¨­å®š
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Gemini Modelè¨­å®š
GEMINI_MODEL = 'gemini-1.5-flash'

def extract_paper_info(soup, url):
    """è«–æ–‡ã®åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º"""
    title = soup.title.string.strip() if soup.title else "Unknown Title"
    
    # arXivã®å ´åˆã®ç‰¹åˆ¥å‡¦ç†
    if "arxiv.org" in url:
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚ˆã‚Šæ­£ç¢ºã«æŠ½å‡º
        title_elem = soup.find('h1', class_='title')
        if title_elem:
            title = title_elem.get_text().replace('Title:', '').strip()
        
        # è‘—è€…æƒ…å ±ã‚’æŠ½å‡º
        authors = []
        authors_elem = soup.find('div', class_='authors')
        if authors_elem:
            author_links = authors_elem.find_all('a')
            authors = [link.get_text().strip() for link in author_links]
        
        # ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’æŠ½å‡º
        abstract = ""
        abstract_elem = soup.find('blockquote', class_='abstract')
        if abstract_elem:
            abstract = abstract_elem.get_text().replace('Abstract:', '').strip()
        
        return {
            'title': title,
            'authors': authors,
            'abstract': abstract,
            'url': url
        }
    
    # ãã®ä»–ã®ã‚µã‚¤ãƒˆã®å ´åˆ
    return {
        'title': title,
        'authors': [],
        'abstract': "",
        'url': url
    }

def generate_summary_with_gemini(paper_info, url):
    """Gemini APIã‚’ä½¿ã£ã¦è«–æ–‡ã®è¦ç´„ã‚’ç”Ÿæˆ"""
    if not GEMINI_API_KEY:
        return None
    
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        
        prompt = f"""
ä»¥ä¸‹ã®è«–æ–‡æƒ…å ±ã‚’åŸºã«ã€è«–æ–‡ã®è¦ç´„ã‚’æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {paper_info['title']}
è‘—è€…: {', '.join(paper_info['authors']) if paper_info['authors'] else 'Unknown'}
ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {paper_info['abstract']}
URL: {url}
ä»¥ä¸‹ã®é …ç›®ã«ã¤ã„ã¦ã€ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

1. ã©ã‚“ãªã‚‚ã®ï¼Ÿï¼ˆç ”ç©¶ã®ç›®çš„ã¨æ¦‚è¦ï¼‰
2. å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ï¼Ÿï¼ˆæ–°è¦æ€§ã¨è²¢çŒ®ï¼‰
3. æŠ€è¡“ã‚„æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã©ã“ï¼Ÿï¼ˆä¸»è¦ãªæŠ€è¡“ãƒ»æ‰‹æ³•ï¼‰
4. ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿï¼ˆå®Ÿé¨“ãƒ»è©•ä¾¡æ–¹æ³•ï¼‰
5. è­°è«–ã¯ã‚ã‚‹ï¼Ÿï¼ˆåˆ¶é™äº‹é …ã‚„ä»Šå¾Œã®èª²é¡Œï¼‰
6. æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ï¼Ÿï¼ˆé–¢é€£ç ”ç©¶ã®ææ¡ˆï¼‰

å„é …ç›®ã¯2-3æ–‡ç¨‹åº¦ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
"""
        
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        print(f"Gemini API ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_keywords_with_gemini(paper_info):
    """Gemini APIã‚’ä½¿ã£ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    if not GEMINI_API_KEY:
        # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯å¾“æ¥ã®æ–¹æ³•ã§æ¤œå‡º
        return detect_research_field_fallback(paper_info)
    
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        
        prompt = f"""
ä»¥ä¸‹ã®è«–æ–‡ã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’5ã¤æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {paper_info['title']}
ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {paper_info['abstract']}

ä»¥ä¸‹ã®å½¢å¼ã§5å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- æŠ€è¡“åï¼ˆä¾‹ï¼šLLM, RAG, Transformerï¼‰
- ç ”ç©¶åˆ†é‡ï¼ˆä¾‹ï¼šNLP, Computer Vision, Roboticsï¼‰
- æ‰‹æ³•åï¼ˆä¾‹ï¼šFine-tuning, Prompt Engineeringï¼‰
- å¿œç”¨åˆ†é‡ï¼ˆä¾‹ï¼šEducation, Healthcare, Financeï¼‰

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è‹±èªã§ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = model.generate_content(prompt)
        keywords_text = response.text.strip()
        # ã‚«ãƒ³ãƒã§åˆ†å‰²ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keywords = [kw.strip() for kw in keywords_text.split(',') if kw.strip()]
        return keywords[:5]  # æœ€å¤§5å€‹ã¾ã§
        
    except Exception as e:
        print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []


def detect_research_field_fallback(paper_info):
    """å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç ”ç©¶åˆ†é‡æ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
    title_lower = paper_info['title'].lower()
    abstract_lower = paper_info['abstract'].lower()
    
    fields = []
    
    # ç ”ç©¶åˆ†é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
    field_keywords = {
        'AI/ML': ['machine learning', 'artificial intelligence', 'deep learning', 'neural network', 'llm', 'large language model'],
        'NLP': ['natural language', 'nlp', 'text', 'language model', 'transformer', 'bert', 'gpt'],
        'Computer Vision': ['computer vision', 'image', 'visual', 'cv', 'detection', 'recognition'],
        'Robotics': ['robot', 'robotics', 'autonomous', 'control'],
        'Education': ['education', 'learning', 'teaching', 'pedagogy', 'classroom', 'student'],
        'Healthcare': ['health', 'medical', 'clinical', 'patient', 'diagnosis'],
        'Finance': ['finance', 'financial', 'trading', 'investment', 'banking'],
        'HCI': ['human-computer interaction', 'hci', 'user interface', 'ux', 'usability'],
        'Software Engineering': ['software', 'development', 'programming', 'code', 'engineering'],
        'Data Science': ['data', 'analytics', 'statistics', 'mining', 'big data']
    }
    
    for field, keywords in field_keywords.items():
        for keyword in keywords:
            if keyword in title_lower or keyword in abstract_lower:
                fields.append(field)
                break
    
    return list(set(fields))  # é‡è¤‡ã‚’é™¤å»

def create_obsidian_template(paper_info, summary=None, keywords=None, research_fields=None):
    """Obsidianãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ"""
    
    # è‘—è€…æƒ…å ±ã®å‡¦ç†
    authors_str = ', '.join(paper_info['authors']) if paper_info['authors'] else ""
    
    # å¹´å·ã®æŠ½å‡ºï¼ˆarXiv URLã‹ã‚‰ï¼‰
    year = date.today().year
    if "arxiv.org" in paper_info['url']:
        try:
            # URLã‹ã‚‰å¹´å·ã‚’æŠ½å‡ºï¼ˆä¾‹: 2505.19443 -> 2025ï¼‰
            arxiv_id = paper_info['url'].split('/')[-1]
            # æœ€åˆã®2æ¡ã‚’å–å¾—(50ä»¥ä¸‹ãªã‚‰2000å¹´å°ã€50ä»¥ä¸Šãªã‚‰1900å¹´å° ã¨ä»®å®š)
            year_prefix = arxiv_id[:2]
            if year_prefix.isdigit():
                year_num = int(year_prefix)
                if year_num <= 50:
                    year = 2000 + year_num
                else:
                    year = 1900 + year_num
        except:
            pass
    
    # ã‚¿ã‚°ã®æ§‹ç¯‰
    tags = []
    
    # ç ”ç©¶åˆ†é‡ã®ã‚¿ã‚°
    if research_fields:
        tags.extend(research_fields)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¿ã‚°
    if keywords:
        tags.extend(keywords)
    
    # è‘—è€…ã‚’ã‚¿ã‚°ã¨ã—ã¦è¿½åŠ ï¼ˆGraph Viewã§è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
    if paper_info['authors']:
        for author in paper_info['authors']:
            # è‘—è€…åã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ã‚¿ã‚°åŒ–
            author_tag = author.replace(' ', '_').replace('.', '').replace(',', '')
            tags.append(f"author/{author_tag}")
    
    # ã‚¿ã‚°æ–‡å­—åˆ—ã®ä½œæˆ
    tags_str = ', '.join([f'"{tag}"' for tag in tags]) if tags else ""
    
    # è‘—è€…ãƒªãƒ³ã‚¯ã®ä½œæˆï¼ˆObsidianã®å†…éƒ¨ãƒªãƒ³ã‚¯å½¢å¼ï¼‰
    author_links = ""
    if paper_info['authors']:
        author_links = "\n## è‘—è€…\n"
        for author in paper_info['authors']:
            author_links += f"- [[{author}]]\n"
    
    md_content = f"""---
title: "{paper_info['title']}"
authors: [{authors_str}]
venue: ""
year: {year}
tags: [{tags_str}]
status: "æœªèª­"
thumbnail: 
pdf: "{paper_info['url']}"
aliases: []
---

{author_links}
## ã©ã‚“ãªã‚‚ã®ï¼Ÿ

{summary.split('1. ã©ã‚“ãªã‚‚ã®ï¼Ÿï¼ˆç ”ç©¶ã®ç›®çš„ã¨æ¦‚è¦ï¼‰')[1].split('2. å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ï¼Ÿï¼ˆæ–°è¦æ€§ã¨è²¢çŒ®ï¼‰')[0].strip() if summary and '1. ã©ã‚“ãªã‚‚ã®ï¼Ÿï¼ˆç ”ç©¶ã®ç›®çš„ã¨æ¦‚è¦ï¼‰' in summary else ''}

## å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ï¼Ÿ

{summary.split('2. å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ï¼Ÿï¼ˆæ–°è¦æ€§ã¨è²¢çŒ®ï¼‰')[1].split('3. æŠ€è¡“ã‚„æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã©ã“ï¼Ÿï¼ˆä¸»è¦ãªæŠ€è¡“ãƒ»æ‰‹æ³•ï¼‰')[0].strip() if summary and '2. å…ˆè¡Œç ”ç©¶ã¨æ¯”ã¹ã¦ã©ã“ãŒã™ã”ã„ï¼Ÿï¼ˆæ–°è¦æ€§ã¨è²¢çŒ®ï¼‰' in summary else ''}

## æŠ€è¡“ã‚„æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã©ã“ï¼Ÿ

{summary.split('3. æŠ€è¡“ã‚„æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã©ã“ï¼Ÿï¼ˆä¸»è¦ãªæŠ€è¡“ãƒ»æ‰‹æ³•ï¼‰')[1].split('4. ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿï¼ˆå®Ÿé¨“ãƒ»è©•ä¾¡æ–¹æ³•ï¼‰')[0].strip() if summary and '3. æŠ€è¡“ã‚„æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã©ã“ï¼Ÿï¼ˆä¸»è¦ãªæŠ€è¡“ãƒ»æ‰‹æ³•ï¼‰' in summary else ''}

## ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿ

{summary.split('4. ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿï¼ˆå®Ÿé¨“ãƒ»è©•ä¾¡æ–¹æ³•ï¼‰')[1].split('5. è­°è«–ã¯ã‚ã‚‹ï¼Ÿï¼ˆåˆ¶é™äº‹é …ã‚„ä»Šå¾Œã®èª²é¡Œï¼‰')[0].strip() if summary and '4. ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸï¼Ÿï¼ˆå®Ÿé¨“ãƒ»è©•ä¾¡æ–¹æ³•ï¼‰' in summary else ''}

## è­°è«–ã¯ã‚ã‚‹ï¼Ÿ

{summary.split('5. è­°è«–ã¯ã‚ã‚‹ï¼Ÿï¼ˆåˆ¶é™äº‹é …ã‚„ä»Šå¾Œã®èª²é¡Œï¼‰')[1].split('6. æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ï¼Ÿï¼ˆé–¢é€£ç ”ç©¶ã®ææ¡ˆï¼‰')[0].strip() if summary and '5. è­°è«–ã¯ã‚ã‚‹ï¼Ÿï¼ˆåˆ¶é™äº‹é …ã‚„ä»Šå¾Œã®èª²é¡Œï¼‰' in summary else ''}

## æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ï¼Ÿ

{summary.split('6. æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ï¼Ÿï¼ˆé–¢é€£ç ”ç©¶ã®ææ¡ˆï¼‰')[1].strip() if summary and '6. æ¬¡ã«èª­ã‚€ã¹ãè«–æ–‡ã¯ï¼Ÿï¼ˆé–¢é€£ç ”ç©¶ã®ææ¡ˆï¼‰' in summary else ''}

## é–¢é€£ãƒªãƒ³ã‚¯

### ç ”ç©¶åˆ†é‡
{chr(10).join([f'- [[{field}]]' for field in (research_fields or [])])}

### ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
{chr(10).join([f'- [[{keyword}]]' for keyword in (keywords or [])])}
"""
    
    return md_content

# å¼•æ•°ã§URLå—ã‘å–ã‚Š
url = sys.argv[1]

# 1. HTMLå–å¾—
print("ğŸ“„ è«–æ–‡ãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­...")
res = requests.get(url)
soup = BeautifulSoup(res.text, "html.parser")

# 2. è«–æ–‡æƒ…å ±ã‚’æŠ½å‡º
print("ğŸ” è«–æ–‡æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
paper_info = extract_paper_info(soup, url)

# 3. Gemini APIã§è¦ç´„ç”Ÿæˆ
print("ğŸ¤– Gemini APIã§è¦ç´„ã‚’ç”Ÿæˆä¸­...")
summary = generate_summary_with_gemini(paper_info, url)

# 4. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã¨ç ”ç©¶åˆ†é‡æ¤œå‡º
print("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ç ”ç©¶åˆ†é‡ã‚’æŠ½å‡ºä¸­...")
keywords = extract_keywords_with_gemini(paper_info)
research_fields = detect_research_field(paper_info)

# 5. Obsidianãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
print("ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
md_content = create_obsidian_template(paper_info, summary, keywords, research_fields)

# 6. Obsidianã®Vaultå†…ã«ä¿å­˜
vault_path = Path.home() / "ObsidianVault" / "Papers"
vault_path.mkdir(parents=True, exist_ok=True)
filename = f"{paper_info['title'].replace(' ', '_').replace('/', '_')}.md"
with open(vault_path / filename, "w", encoding='utf-8') as f:
    f.write(md_content)

print(f"âœ… {filename} ã‚’ Obsidian ã«ä½œæˆã—ã¾ã—ãŸ")
if summary:
    print("âœ¨ Gemini APIã«ã‚ˆã‚‹è¦ç´„ãŒå®Œäº†ã—ã¾ã—ãŸ")
else:
    print("âš ï¸  Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
